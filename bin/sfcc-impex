#!/usr/bin/env bash
set -e
[ -n "$DEBUG" ] && set -x

#
# download files from Impex folder
#
# USAGE
#
#    sfcc impex [options] [path] [filename-pattern]
#
# OPTIONS
#
#    -d            download (only new files)
#    -k            delete using filename-pattern
#    -K            delete a specific file
#    -f            force download (if file already exists in CWD)
#    -c N          limit number of file to N
#    -P            day histogram
#    -p DATE       hour histogram for DATE [default: today]
#    -I            list instances
#    -i NAME       use NAME as instances (and set as default)
#    -z D          zip & delete files older than D days [default: 7 days]
#    --no-color    do not print colors to stdout
#    -n NUM        number of parallel downloads [default: 1, max: 8]
#
# EXAMPLES
#
#    sfcc impex archive/catalog
#    sfcc impex -d log import-catalog-20190617
#    sfcc impex -P
#    sfcc impex -p 2019-05-03
#    sfcc impex -k archive/catalog 2019-05-03              // delete all files matchin a pattern in archive/catalog
#    sfcc impex -K archive/catalog/2019-09-25.xml          // delete a specific file
#

config="$HOME/.sfcc-impex"
basepath="/on/demandware.servlet/webdav/Sites/Impex/"
if [ -f $config ]; then
  host_envname="SFCC_HOST_$(cat $config)"
  host=${!host_envname}
  user_envname="SFCC_USER_$(cat $config)"
  user=${!user_envname}
fi
folder=""


histogram() {
  local max_value=`cat $1 | sort -n | tail -1 | awk '{print $1}'`
  local label_width=$2
  local num_cols="$(( `tput cols` - label_width - `echo -n $max_value | wc -c` - 10 ))"
  local step="$(( $max_value / $num_cols + 1 ))"
  if [ $step == 0 ]; then step=1; fi

  cat $datafile \
    | awk -v S="$step" -v Y=`tput setaf 3` -v R=`tput sgr0` -v G=`tput setaf 0` '{printf("\n  %s %s", $2, Y); for(i=0; i<$1; i+=S){printf("#")}; if ($1 > 0) {printf(" %s(%s)", G, $1)}; printf("%s", R)}' \
    | sort -n
}

duration_plot() {
  echo -e "\n Time [in minutes] from file-generation to import\n\n $1:"
  local datafile=`mktemp ./daily-plot-XXXXX`
  trap "rm $datafile" EXIT
  for f in `ls | grep -e "\.xml$" | grep "^$1"`; do
    local from=$(echo $f | perl -pe 's/^(.*?)_.*/\1/g')
    local to=$(echo $f | perl -pe 's/.*_(.*?)\.xml$/\1/g')
    local duration=$(( $(date -j -f "%Y-%m-%d-%H%M%S" $to +%s) - $(date -j -f "%Y-%m-%dT%H%M%S" $from +%s) ))
    echo "scale=0;$duration/60" | bc
  done | sort | uniq -c > $datafile
  histogram $datafile 10
}

daily_plot() {
  local datafile=`mktemp ./daily-plot-XXXXX`
  trap "rm $datafile" EXIT
  ls | grep -e "\.xml$" | perl -pe 's/^(\d{4}-\d{2}-\d{2}).*/\1/g' | sort | uniq -c > $datafile
  histogram $datafile 10
}

hourly_plot() {
  echo -e "\n $1:"
  local datafile=`mktemp ./hourly-plot-XXXXX`
  local datafile2=`mktemp ./hourly-plot-XXXXX-2`
  trap "rm $datafile $datafile2" EXIT
  ls | grep -e "\.xml$" | grep "^$1" | perl -pe 's/^'${1}'T(\d{2}).*/\1/g' | sort | uniq -c > $datafile2

  # fill empty hours
  for i in {00..23}; do
    n=`awk '/'${i}'$/ {print $2}' $datafile2`
    cn=`awk '/'${i}'$/ {print $0}' $datafile2`
    if [ "$i" == "$n" ]; then
      echo $cn
    else
      echo 0 $i
    fi
  done > $datafile
  histogram $datafile 2
}

list_instances() {
  local instance=`cat $config`
  echo ''
  env \
    | grep SFCC_HOST \
    | perl -pe 's/^SFCC_HOST_(.*)=(.*)$/\1 \2/g' \
    | awk -v I="$instance" -v G=`tput setaf 2` -v R=`tput sgr0` '{M=" ";if(I == $1){M="*"};printf(" %s %s%s%s#%s\n"), M, G, $1, R, $2 }' \
    | column -t -s '#'
}

archive-and-delete() {
  local days=${1-7}
  for file in `find . -name "*.xml"`; do
    local d=$(date -v -${days}d +"%s")
    local cd=$(date -j -f "%Y-%m-%d" ${file:2:10} +"%s")
    if [ $(( $cd - $d )) -lt 0 ]; then
      zip "`basename $PWD`-${file:2:10}.zip" $file
      rm $file
    fi
  done
}

parallel=1

while test $# -ne 0; do
  arg=$1
  shift
  case $arg in
    -h|--help)
      cat $0 | sed -n '/^#/p' | sed '/^##/d' | sed 1d | sed 's/#/ /g' \
        | perl -pe "s/(USAGE|OPTIONS|EXAMPLES)/$(tput setaf 0)\1$(tput sgr0)/"
      exit 1
      ;;
    -t|--duration-histogram)
      duration_plot ${1:-`date +"%Y-%m-%d"`}
      exit 0
      ;;
    -P|--day-histogram)
      daily_plot
      exit 0
      ;;
    -I|--instances)
      list_instances
      exit 0
      ;;
    -i|--instance)
      echo $1 > ${config}
      host_envname="SFCC_HOST_$1"
      host=${!host_envname}
      user_envname="SFCC_USER_$1"
      user=${!user_envname}
      shift
      ;;
    -p|--hour-histogram)
      hourly_plot ${1:-`date +"%Y-%m-%d"`}
      exit 0
      ;;
    -z|--zip)
      archive-and-delete $1
      exit 0
      ;;
    --no-color)
      no_color=1
      ;;
    -d|--download)
      download=1
      ;;
    -n)
      parallel=$1
      if [ $parallel -lt 1 -o $parallel -gt 8 ]; then
        echo "maximum of $(tput setaf 1)8$(tput sgr0) parallel downloads"
        exit 1
      fi
      ;;
    -k|--kill)
      delete=1
      ;;
    -K)
      deleteFile=$1
      ;;
    -f|--force)
      force_download=1
      ;;
    -c|--count)
      count=$1
      shift
      ;;
    *)
      if [ $# -eq 1 ]; then
        folder=$arg
        arg=$1
        shift
        filepattern=$arg
      else
        folder=$arg
      fi
      ;;
  esac
done

if [ $deleteFile ]; then
  echo "$(tput setaf 1)[X]$(tput sgr0) ${deleteFile}"
  curl -s -u "${user}" -X DELETE "https://${host}${deleteFile}"
fi

urlfile=`mktemp ./url-XXXXX`
trap "rm $urlfile" EXIT

curl -sN -u "$user" "https://${host}${basepath}${folder}" \
  | sed -n '/.*<a href="\(.*\)"><tt>.*/p' \
  | sed 's/.*<a href="\(.*\)"><tt>.*/\1/g' \
  | ( [[ $filepattern ]] && sed -n /$filepattern/p || cat ) \
  | ( [[ $count ]] && head -n $count || cat ) \
  > $urlfile
total=`wc -l $urlfile | awk '{print $1}'`

download_count=0
download() {
  local url=$1
  local total=$2
  local i=$3
  local user=$4
  local host=$5
  local file="`echo $url | sed 's/.*\/\(.*\)/\1/g'`"
  if [ ! -f $file ] || [ $force_download ]; then
    if [ -z $no_color ]; then
      echo "$(tput setaf 2)[$i/$total]$(tput sgr0) $file"
    else
      echo "[$i/$total] $file"
    fi
    curl -s -u "$user" -O "https://${host}${url}"
    if [ ${file: -4} == ".xml" ]; then
      xml fo $file > temp && mv temp $file || echo $file >> fo-error.txt
    fi
  else
    echo "[$i/$total] $file"
  fi
}
export -f download

if [ $download ]; then
  while mapfile -t -n${parallel} ary && ((${#ary[@]})); do
    download_count=$(($download_count+1))
    printf '%s\n' "${ary[@]}" | xargs -n1 -P${parallel} -I {} sh -c "download {} ${total} $((${download_count}*${parallel})) ${user} ${host}"
  done < $urlfile
elif [ $delete ]; then
  i=0
  while ((i++)); read -r url; do
    file="`echo $url | sed 's/.*\/\(.*\)/\1/g'`"
    if [ -z $no_color ]; then
      echo "$(tput setaf 1)[$i/$total]$(tput sgr0) $file"
    else
      echo "[$i/$total] $file"
    fi
    curl -s -u "$user" -X DELETE "https://${host}${url}"
  done < $urlfile
else
  echo -e "\n$(tput setaf 2)${host}$(tput sgr0)\n"
  if [ -z $no_color ]; then
    if [ -z $folder ]; then
      cat $urlfile | perl -pe 's/(Impex\/)(.*)$/\1'$(tput setaf 2)'\2'$(tput sgr0)'/g'
    else
      cat $urlfile | perl -pe 's/(Impex\/'${folder//\//\\/}'\/)(.*)$/\1'$(tput setaf 2)'\2'$(tput sgr0)'/g'
    fi
  else
    cat $urlfile
  fi
fi

exit 0
